# Word Representations via Dirichlet Embeddings

We build off prior work in [embedding words as Gaussian
distributions](https://arxiv.org/abs/1412.6623), with the goal of [moving beyond
word embeddings as
points](http://ruder.io/word-embeddings-2017/index.html#beyondwordsaspoints).
We investigate whether using Dirichlet distributions allows for more expressive
word representations.
